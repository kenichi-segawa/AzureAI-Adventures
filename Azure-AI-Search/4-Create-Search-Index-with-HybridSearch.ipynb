{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "# Azure AI Search integrated vectorization sample\n",
        "\n",
        "This Python notebook demonstrates the [integrated vectorization](https://learn.microsoft.com/azure/search/vector-search-integrated-vectorization) features of Azure AI Search that are currently in public preview. \n",
        "\n",
        "Integrated vectorization takes a dependency on indexers and skillsets, using the Text Split skill for data chunking, and the AzureOpenAIEmbedding skill and your Azure OpenAI resorce for embedding.\n",
        "\n",
        "This example uses PDFs from the `data/documents` folder for chunking, embedding, indexing, and queries.\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "+ An Azure subscription, with [access to Azure OpenAI](https://aka.ms/oai/access).\n",
        " \n",
        "+ Azure AI Search, any tier, but we recommend Basic or higher for this workload. [Enable semantic ranker](https://learn.microsoft.com/azure/search/semantic-how-to-enable-disable) if you want to run a hybrid query with semantic ranking.\n",
        "\n",
        "+ A deployment of the `text-embedding-ada-002` model on Azure OpenAI.\n",
        "\n",
        "+ Azure Blob Storage. This notebook connects to your storage account and loads a container with the sample PDFs.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up a Python virtual environment in Visual Studio Code\n",
        "\n",
        "1. Open the Command Palette (Ctrl+Shift+P).\n",
        "1. Search for **Python: Create Environment**.\n",
        "1. Select **Venv**.\n",
        "1. Select a Python interpreter. Choose 3.10 or later.\n",
        "\n",
        "It can take a minute to set up. If you run into problems, see [Python environments in VS Code](https://code.visualstudio.com/docs/python/environments)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install packages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r azure-search-integrated-vectorization-sample-requirements.txt --quiet"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load .env file (Copy .env-sample to .env and update accordingly)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "import os\n",
        "\n",
        "load_dotenv(override=True) # take environment variables from .env.\n",
        "\n",
        "# Variables not used here do not need to be updated in your .env file\n",
        "endpoint = os.environ[\"AZURE_SEARCH_SERVICE_ENDPOINT\"]\n",
        "credential = AzureKeyCredential(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) if len(os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]) > 0 else DefaultAzureCredential()\n",
        "\n",
        "blob_connection_string = os.environ[\"AZURE_STORAGE_CONNECTION_STRING\"]\n",
        "blob_container_name = os.environ[\"AZURE_STORAGE_CONTAINER_NAME\"]\n",
        "azure_openai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        "azure_openai_key = os.environ[\"AZURE_OPENAI_API_KEY\"] if len(os.environ[\"AZURE_OPENAI_API_KEY\"]) > 0 else None\n",
        "azure_openai_embedding_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL\"]\n",
        "print(\"envrioment variables loaded successfully.\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740413020
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Blob Storage and load documents\n",
        "\n",
        "Retrieve documents from Blob Storage. You can use the sample documents in the data/documents folder.  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.storage.blob import BlobServiceClient  \n",
        "import os\n",
        "\n",
        "# Connect to Blob Storage\n",
        "blob_service_client = BlobServiceClient.from_connection_string(blob_connection_string)\n",
        "container_client = blob_service_client.get_container_client(blob_container_name)\n",
        "if not container_client.exists():\n",
        "    container_client.create_container()\n",
        "\n",
        "# upload data to blob storage\n",
        "documents_directory = os.path.join(\"data\")\n",
        "for file in os.listdir(documents_directory): \n",
        "    if not file.endswith(\".amlignore\") and not file.endswith(\".amlignore.amltmp\"):\n",
        "        with open(os.path.join(documents_directory, file), \"rb\") as data:\n",
        "            name = os.path.basename(file)\n",
        "            if not container_client.get_blob_client(name).exists():\n",
        "                print(f'Uploading {name} to blob storage...')\n",
        "                container_client.upload_blob(name=name, data=data)\n",
        "\n",
        "print(f\"\\nSetup sample data in {blob_container_name}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740414007
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a blob data source connector on Azure AI Search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes import SearchIndexerClient\n",
        "from azure.search.documents.indexes.models import (\n",
        "    SearchIndexerDataContainer,\n",
        "    SearchIndexerDataSourceConnection\n",
        ")\n",
        "\n",
        "index_name = 'integerated-vectorization-sample-index'\n",
        "\n",
        "# Create a data source \n",
        "indexer_client = SearchIndexerClient(endpoint, credential)\n",
        "container = SearchIndexerDataContainer(name=blob_container_name)\n",
        "data_source_connection = SearchIndexerDataSourceConnection(\n",
        "    name=f\"{index_name}-blob\",\n",
        "    type=\"azureblob\",\n",
        "    connection_string=blob_connection_string,\n",
        "    container=container\n",
        ")\n",
        "\n",
        "# check if index_name exists\n",
        "try:\n",
        "    data_source = indexer_client.get_data_source_connection(data_source_connection.name)\n",
        "    print(f\"Data source '{data_source.name}' already exists\")\n",
        "except:\n",
        "    data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
        "    print(f\"Data source '{data_source.name}' created or updated\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740414851
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a search index\n",
        "\n",
        "Vector and nonvector content is stored in a search index."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip uninstall -y azure-search-documents \n",
        "# ! pip install azure-search-documents==11.6.0b1\n",
        "# anaconda envrioment switch: https://stackoverflow.com/questions/63934091/switch-between-anaconda-virtual-environments-and-uses-of-activate-deactivate-rem"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740415990
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes import SearchIndexClient\n",
        "from azure.search.documents.indexes.models import (\n",
        "    SearchField,\n",
        "    SearchFieldDataType,\n",
        "    VectorSearch,\n",
        "    HnswAlgorithmConfiguration,\n",
        "    HnswParameters,\n",
        "    VectorSearchAlgorithmMetric,\n",
        "    ExhaustiveKnnAlgorithmConfiguration,\n",
        "    ExhaustiveKnnParameters,\n",
        "    VectorSearchProfile,\n",
        "    AzureOpenAIVectorizer,\n",
        "    AzureOpenAIParameters,\n",
        "    SemanticConfiguration,\n",
        "    SemanticSearch,\n",
        "    SemanticPrioritizedFields,\n",
        "    SemanticField,\n",
        "    SearchIndex\n",
        ")\n",
        "\n",
        "# Create a search index  \n",
        "# Vector search algorithms include exhaustive k-nearest neighbors (KNN) and Hierarchical Navigable Small World (HNSW)\n",
        "index_client = SearchIndexClient(endpoint=endpoint, credential=credential)  \n",
        "fields = [  \n",
        "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String, sortable=True, filterable=True, facetable=True),  \n",
        "    SearchField(name=\"title\", type=SearchFieldDataType.String),  \n",
        "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),  \n",
        "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),  \n",
        "    SearchField(name=\"vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\"),  \n",
        "]  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740416523
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the vector search configuration  \n",
        "vector_search = VectorSearch(  \n",
        "    algorithms=[  \n",
        "        # Contains configuration options specific to the HNSW approximate nearest neighbors algorithm used during indexing and querying. \n",
        "        # The HNSW algorithm offers a tunable trade-off between search speed and accuracy.\n",
        "        HnswAlgorithmConfiguration(  \n",
        "            name=\"myHnsw\",  \n",
        "            parameters=HnswParameters(  \n",
        "                m=4,  \n",
        "                ef_construction=400,  \n",
        "                ef_search=500,  \n",
        "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
        "            ),  \n",
        "        ),  \n",
        "\n",
        "        # Contains configuration options specific to the exhaustive KNN algorithm used during querying, which will perform brute-force search across the entire vector index\n",
        "        ExhaustiveKnnAlgorithmConfiguration(  \n",
        "            name=\"myExhaustiveKnn\",  \n",
        "            parameters=ExhaustiveKnnParameters(  \n",
        "                metric=VectorSearchAlgorithmMetric.COSINE,  \n",
        "            ),  \n",
        "        ),  \n",
        "    ],  \n",
        "\n",
        "    profiles=[  \n",
        "        VectorSearchProfile(  \n",
        "            name=\"myHnswProfile\",  \n",
        "            algorithm_configuration_name=\"myHnsw\",  \n",
        "            vectorizer=\"myOpenAI\",  \n",
        "        ),  \n",
        "        VectorSearchProfile(  \n",
        "            name=\"myExhaustiveKnnProfile\",  \n",
        "            algorithm_configuration_name=\"myExhaustiveKnn\",  \n",
        "            vectorizer=\"myOpenAI\",  \n",
        "        ),  \n",
        "    ], \n",
        "     \n",
        "    vectorizers=[  \n",
        "        AzureOpenAIVectorizer(  \n",
        "            name=\"myOpenAI\",  \n",
        "            kind=\"azureOpenAI\",  \n",
        "            azure_open_ai_parameters=AzureOpenAIParameters(  \n",
        "                resource_uri=azure_openai_endpoint,  \n",
        "                deployment_id=azure_openai_embedding_deployment,  \n",
        "                api_key=azure_openai_key,  \n",
        "            ),  \n",
        "        ),  \n",
        "    ],  \n",
        ") "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740421358
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_config = SemanticConfiguration(  \n",
        "    name=\"my-semantic-config\",  \n",
        "    prioritized_fields=SemanticPrioritizedFields(  \n",
        "        content_fields=[SemanticField(field_name=\"chunk\")]  \n",
        "    ),  \n",
        ")  \n",
        "  \n",
        "# Create the semantic search with the configuration  \n",
        "semantic_search = SemanticSearch(configurations=[semantic_config])  \n",
        "  \n",
        "# check the search index, create if not exist\n",
        "try:\n",
        "    index = index_client.get_index(index_name)\n",
        "    print(f\"Index '{index.name}' already exists\")\n",
        "except:\n",
        "    index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search, semantic_search=semantic_search)  \n",
        "    result = index_client.create_or_update_index(index)  \n",
        "    print(f\"{result.name} created\")  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740422217
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a skillset\n",
        "\n",
        "Skills drive integrated vectorization. [Text Split](https://learn.microsoft.com/azure/search/cognitive-search-skill-textsplit) provides data chunking. [AzureOpenAIEmbedding](https://learn.microsoft.com/azure/search/cognitive-search-skill-azure-openai-embedding) handles calls to Azure OpenAI, using the connection information you provide in the environment variables. An [indexer projection](https://learn.microsoft.com/azure/search/index-projections-concept-intro) specifies secondary indexes used for chunked data."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes.models import (\n",
        "    SplitSkill,\n",
        "    InputFieldMappingEntry,\n",
        "    OutputFieldMappingEntry,\n",
        "    AzureOpenAIEmbeddingSkill,\n",
        "    SearchIndexerIndexProjections,\n",
        "    SearchIndexerIndexProjectionSelector,\n",
        "    SearchIndexerIndexProjectionsParameters,\n",
        "    IndexProjectionMode,\n",
        "    SearchIndexerSkillset\n",
        ")\n",
        "\n",
        "# Create a skillset  \n",
        "skillset_name = f\"{index_name}-skillset\"  \n",
        "  \n",
        "split_skill = SplitSkill(  \n",
        "    description=\"Split skill to chunk documents\",  \n",
        "    text_split_mode=\"pages\",  \n",
        "    context=\"/document\",  \n",
        "    maximum_page_length=2000,  \n",
        "    page_overlap_length=500,  \n",
        "    inputs=[  \n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),  \n",
        "    ],  \n",
        "    outputs=[  \n",
        "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")  \n",
        "    ],  \n",
        ")  \n",
        "  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740423983
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_skill = AzureOpenAIEmbeddingSkill(  \n",
        "    description=\"Skill to generate embeddings via Azure OpenAI\",  \n",
        "    context=\"/document/pages/*\",  \n",
        "    resource_uri=azure_openai_endpoint,  \n",
        "    deployment_id=azure_openai_embedding_deployment,  \n",
        "    api_key=azure_openai_key,  \n",
        "    inputs=[  \n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),  \n",
        "    ],  \n",
        "    outputs=[  \n",
        "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"vector\")  \n",
        "    ],  \n",
        ")  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713740426797
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The skillset will first split the document into pages, then generate embeddings for each page.\n",
        "# The embeddings will be stored in the \"vector\" field of the index.\n",
        "# The \"title\" field will be used as the title of the document.\n",
        "# The \"chunk\" field will be used to store the text of each page.\n",
        "# The \"parent_id\" field will be used to group pages together.\n",
        "# The \"chunk_id\" field will be used to uniquely identify each page.\n",
        "# The \"vector\" field will be used to store the embeddings generated by the Azure OpenAI Embedding Skill.\n",
        "# The \"myHnswProfile\" vector search profile will be used to index the embeddings.\n",
        "# The \"my-semantic-config\" semantic configuration will be used to perform semantic search.\n",
        "\n",
        "# what's index projections used for?\n",
        "# Index projections allow you to specify which fields from the parent document should be indexed in the child documents.\n",
        "# This is useful when you want to index only a subset of the fields from the parent document in the child documents.\n",
        "# In this case, we are indexing the \"chunk\" and \"vector\" fields from the parent document in the child documents.\n",
        "# We are also indexing the \"title\" field from the parent document in the child documents.\n",
        "# The \"projection_mode\" parameter specifies how the parent document should be indexed.\n",
        "# In this case, we are skipping the indexing of the parent document.\n",
        "# This means that only the child documents will be indexed, and the parent document will not be indexed.\n",
        "\n",
        "index_projections = SearchIndexerIndexProjections(  \n",
        "    selectors=[  \n",
        "        SearchIndexerIndexProjectionSelector(  \n",
        "            target_index_name=index_name,  \n",
        "            parent_key_field_name=\"parent_id\",  \n",
        "            source_context=\"/document/pages/*\",  \n",
        "            mappings=[  \n",
        "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),  \n",
        "                InputFieldMappingEntry(name=\"vector\", source=\"/document/pages/*/vector\"),  \n",
        "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),  \n",
        "            ],  \n",
        "        ),  \n",
        "    ],  \n",
        "    parameters=SearchIndexerIndexProjectionsParameters(  \n",
        "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS  \n",
        "    ),  \n",
        ")  \n",
        "  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711650437806
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skillset = SearchIndexerSkillset(  \n",
        "    name=skillset_name,  \n",
        "    description=\"Skillset to chunk documents and generating embeddings\",  \n",
        "    skills=[split_skill, embedding_skill],  \n",
        "    index_projections=index_projections,  \n",
        ")  \n",
        "  \n",
        "client = SearchIndexerClient(endpoint, credential)  \n",
        "\n",
        "# check the skillset, create if not exist\n",
        "try:\n",
        "    skillset = client.get_skillset(skillset_name)\n",
        "    print(f\"Skillset '{skillset.name}' already exists\")\n",
        "except:\n",
        "    client.create_or_update_skillset(skillset)  \n",
        "    print(f\"{skillset.name} created\")  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711650442270
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create an indexer"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes.models import (\n",
        "    SearchIndexer,\n",
        "    FieldMapping\n",
        ")\n",
        "\n",
        "# Create an indexer  \n",
        "indexer_name = f\"{index_name}-indexer\"  \n",
        "  \n",
        "indexer = SearchIndexer(  \n",
        "    name=indexer_name,  \n",
        "    description=\"Indexer to index documents and generate embeddings\",  \n",
        "    skillset_name=skillset_name,  \n",
        "    target_index_name=index_name,  \n",
        "    data_source_name=data_source.name,  \n",
        "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")]  \n",
        ")  \n",
        "\n",
        "# check the indexer, create if not exist\n",
        "indexer_client = SearchIndexerClient(endpoint, credential)  \n",
        "\n",
        "try:\n",
        "    indexer = indexer_client.get_indexer(indexer_name)\n",
        "    print(f\"Indexer '{indexer.name}' already exists\")\n",
        "except:\n",
        "    indexer_result = indexer_client.create_or_update_indexer(indexer)  \n",
        "    print(f'{indexer_name} is created and running. If queries return no results, please wait a bit and try again.')  \n",
        "  \n",
        "# Run the indexer  \n",
        "indexer_client.run_indexer(indexer_name)  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711650469020
        }
      }
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "source": [
        "## Perform a vector similarity search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example shows a pure vector search using the vectorizable text query, all you need to do is pass in text and your vectorizer will handle the query vectorization.\n",
        "\n",
        "If you indexed the health plan PDF file, send queries that ask plan-related questions."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.models import VectorizableTextQuery\n",
        "\n",
        "# Pure Vector Search\n",
        "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"  \n",
        "  \n",
        "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
        "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
        "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
        "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
        "  \n",
        "results = search_client.search(  \n",
        "    search_text=None,  \n",
        "    vector_queries= [vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
        "    top=1\n",
        ")  \n",
        "  \n",
        "for result in results:  \n",
        "    print(f\"parent_id: {result['parent_id']}\")  \n",
        "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
        "    print(f\"Score: {result['@search.score']}\")  \n",
        "    print(f\"Content: {result['chunk']}\")   \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711651916563
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform a hybrid search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid Search\n",
        "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"  \n",
        "  \n",
        "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
        "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
        "  \n",
        "results = search_client.search(  \n",
        "    search_text=query,  \n",
        "    vector_queries= [vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
        "    top=1\n",
        ")  \n",
        "  \n",
        "for result in results:  \n",
        "    print(f\"parent_id: {result['parent_id']}\")  \n",
        "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
        "    print(f\"Score: {result['@search.score']}\")  \n",
        "    print(f\"Content: {result['chunk']}\")  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711651982753
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform a hybrid search + semantic reranking"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.models import (\n",
        "    QueryType,\n",
        "    QueryCaptionType,\n",
        "    QueryAnswerType\n",
        ")\n",
        "# Semantic Hybrid Search\n",
        "query = \"Which is more comprehensive, Northwind Health Plus vs Northwind Standard?\"\n",
        "\n",
        "search_client = SearchClient(endpoint, index_name, credential)\n",
        "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"vector\", exhaustive=True)\n",
        "\n",
        "results = search_client.search(  \n",
        "    search_text=query,\n",
        "    vector_queries=[vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"chunk\"],\n",
        "    query_type=QueryType.SEMANTIC,\n",
        "    semantic_configuration_name='my-semantic-config',\n",
        "    query_caption=QueryCaptionType.EXTRACTIVE,\n",
        "    query_answer=QueryAnswerType.EXTRACTIVE,\n",
        "    top=1\n",
        ")\n",
        "\n",
        "semantic_answers = results.get_answers()\n",
        "if semantic_answers:\n",
        "    for answer in semantic_answers:\n",
        "        if answer.highlights:\n",
        "            print(f\"Semantic Answer: {answer.highlights}\")\n",
        "        else:\n",
        "            print(f\"Semantic Answer: {answer.text}\")\n",
        "        print(f\"Semantic Answer Score: {answer.score}\\n\")\n",
        "\n",
        "for result in results:\n",
        "    print(f\"parent_id: {result['parent_id']}\")  \n",
        "    print(f\"chunk_id: {result['chunk_id']}\")  \n",
        "    print(f\"Reranker Score: {result['@search.reranker_score']}\")\n",
        "    print(f\"Content: {result['chunk']}\")  \n",
        "\n",
        "    captions = result[\"@search.captions\"]\n",
        "    if captions:\n",
        "        caption = captions[0]\n",
        "        if caption.highlights:\n",
        "            print(f\"Caption: {caption.highlights}\\n\")\n",
        "        else:\n",
        "            print(f\"Caption: {caption.text}\\n\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1711651998536
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}